{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "participants_df = pd.read_csv('/content/participants_66dd0f5d2d96edbedcf4a80b.csv')\n",
    "responses_df = pd.read_csv('/content/responses_66dd0f5d2d96edbedcf4a80b.csv')\n",
    "llm_df = pd.read_csv('/content/llm_66dd0f5d2d96edbedcf4a80b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers and colors\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Yellow\n",
    "\n",
    "# Convert string responses to numeric values\n",
    "def convert_ai_feelings(response):\n",
    "    if response == 'More concerned than excited':\n",
    "        return 1\n",
    "    elif response == 'Equally excited and concerned':\n",
    "        return 2\n",
    "    elif response == 'More excited than concerned':\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "participants_df['ai_feelings_before'] = participants_df['Increased use of AI computer programs in daily life makes you feel (before)'].apply(convert_ai_feelings)\n",
    "participants_df['ai_feelings_after'] = participants_df['Increased use of AI computer programs in daily life makes you feel (after)'].apply(convert_ai_feelings)\n",
    "\n",
    "# Rename conditions\n",
    "conditions = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "\n",
    "# Calculate means and SEM for creativity score\n",
    "def calculate_stats(data, column, condition):\n",
    "    condition_data = data[data['condition'] == condition][column]\n",
    "    mean = condition_data.mean()\n",
    "    sem = condition_data.sem()\n",
    "    return mean, sem\n",
    "\n",
    "stats = {}\n",
    "for condition, renamed_condition in conditions.items():\n",
    "    stats[renamed_condition] = {}\n",
    "    stats[renamed_condition]['creative_before'] = calculate_stats(participants_df, 'I am more creative than \\% of humans (before)', condition)\n",
    "    stats[renamed_condition]['creative_after'] = calculate_stats(participants_df, 'I am more creative than \\% of humans (after)', condition)\n",
    "    stats[renamed_condition]['ai_before'] = calculate_stats(participants_df, 'ai_feelings_before', condition)\n",
    "    stats[renamed_condition]['ai_after'] = calculate_stats(participants_df, 'ai_feelings_after', condition)\n",
    "\n",
    "# Calculate means and SEM for AI feelings\n",
    "for condition, renamed_condition in conditions.items():\n",
    "    stats[renamed_condition]['ai_before'] = calculate_stats(participants_df, 'ai_feelings_before', condition)\n",
    "    stats[renamed_condition]['ai_after'] = calculate_stats(participants_df, 'ai_feelings_after', condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Difference in Creativity Score\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Plot the difference in \"I am more creative than % of humans (after - before)\"\n",
    "for i, renamed_condition in enumerate(conditions.values()):\n",
    "    diff_mean = stats[renamed_condition]['creative_after'][0] - stats[renamed_condition]['creative_before'][0]\n",
    "    diff_sem = np.sqrt(stats[renamed_condition]['creative_before'][1]**2 + stats[renamed_condition]['creative_after'][1]**2)\n",
    "    ax1.errorbar([renamed_condition], [diff_mean], yerr=[diff_sem],\n",
    "                 capsize=8, marker=markers[i], linestyle='', markersize=12, color=colors[i], linewidth=3)\n",
    "\n",
    "ax1.set_title('Difference in Self-Assessment of Creativity (After - Before)')\n",
    "ax1.set_xlabel('Condition', fontsize=14)\n",
    "ax1.set_ylabel('Difference in Creativity Score', fontsize=14)\n",
    "ax1.axhline(0, color='gray', linewidth=0.5)  # Add horizontal line at 0\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax1.grid(False)\n",
    "for spine in ax1.spines.values():\n",
    "    spine.set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Difference in Feelings About AI Usage (After - Before)\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Plot the delta (After - Before) for \"Feelings about AI\"\n",
    "for i, renamed_condition in enumerate(conditions.values()):\n",
    "    diff_mean = stats[renamed_condition]['ai_after'][0] - stats[renamed_condition]['ai_before'][0]\n",
    "    diff_sem = np.sqrt(stats[renamed_condition]['ai_before'][1]**2 + stats[renamed_condition]['ai_after'][1]**2)\n",
    "    ax2.errorbar([renamed_condition], [diff_mean], yerr=[diff_sem],\n",
    "                 capsize=10, marker=markers[i], linestyle='', markersize=12, color=colors[i], linewidth=3)\n",
    "\n",
    "ax2.set_title('Change (Δ) in Feelings About AI Usage (After - Before)')\n",
    "ax2.set_xlabel('Condition')\n",
    "ax2.set_ylabel('Change in AI Feeling Score')\n",
    "ax2.axhline(0, color='gray', linewidth=0.5)  # Add horizontal line at 0\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax2.grid(False)\n",
    "for spine in ax2.spines.values():\n",
    "    spine.set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi Squared, p-value, Degrees of Freedom, Expected Frequencies\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Count the number of participants by condition\n",
    "counts = participants_df['condition'].value_counts().reset_index()\n",
    "counts.columns = ['condition', 'count']\n",
    "\n",
    "# Display the counts in a table format\n",
    "print(counts)\n",
    "\n",
    "# Convert counts to a contingency table (1-dimensional in this case)\n",
    "# Since it's a single dimension, we need to add a dummy dimension for chi2_contingency\n",
    "contingency_table = counts['count'].values.reshape(1, -1)\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the chi-square test result\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"p-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: How difficult was it to come up with uses for the last object?\n",
    "\n",
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "participants_df['condition_renamed'] = participants_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Convert string responses to numeric values for difficulty\n",
    "difficulty_mapping = {\n",
    "    'Very easy': 1,\n",
    "    'Somewhat easy': 2,\n",
    "    'Neither easy nor difficult': 3,\n",
    "    'Somewhat difficult': 4,\n",
    "    'Very difficult': 5\n",
    "}\n",
    "participants_df['difficulty'] = participants_df['How difficult was it to come up with uses for the last object?'].map(difficulty_mapping)\n",
    "\n",
    "# Calculate means and SEM for difficulty by condition\n",
    "difficulty_stats = participants_df.groupby('condition_renamed')['difficulty'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "difficulty_stats['condition_renamed'] = pd.Categorical(difficulty_stats['condition_renamed'], categories=order, ordered=True)\n",
    "difficulty_stats = difficulty_stats.sort_values('condition_renamed')\n",
    "\n",
    "# Define color scheme and markers\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Blue\n",
    "markers = ['o', 's', 'D']  # Circle, Square, Diamond\n",
    "\n",
    "# Plot mean +- sem for difficulty\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "for i, condition in enumerate(difficulty_stats['condition_renamed']):\n",
    "    ax.errorbar([condition], [difficulty_stats['mean'].iloc[i]], yerr=[difficulty_stats['sem'].iloc[i]],\n",
    "                fmt=markers[i], capsize=10, markersize=12, color=colors[i], linewidth=3)\n",
    "\n",
    "ax.set_title('Difficulty in Coming Up with Uses for the Last Object')\n",
    "ax.set_xlabel('Condition', fontsize=14)\n",
    "ax.set_ylabel('Difficulty Score', fontsize=14)\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Originality Scores by Condition and Phase\n",
    "\n",
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Calculate mean and SEM for originality in llm_df (no conditions)\n",
    "llm_mean = llm_df['originality'].mean()\n",
    "llm_sem = llm_df['originality'].sem()\n",
    "\n",
    "# Calculate means and SEM for originality by condition and phase\n",
    "originality_stats_phase = responses_df.groupby(['condition_renamed', 'phase'])['originality'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "originality_stats_phase['condition_renamed'] = pd.Categorical(originality_stats_phase['condition_renamed'], categories=order, ordered=True)\n",
    "originality_stats_phase = originality_stats_phase.sort_values(['condition_renamed', 'phase'])\n",
    "\n",
    "# Define color scheme, markers, linestyles, and offsets\n",
    "colors = ['#7F7F7F', '#E57A77', '#3D65A5']  # Gray, Red, Blue\n",
    "markers = ['o', 's', 'D']  # Circle, Square, Diamond\n",
    "linestyles = ['-', '--', ':']\n",
    "offsets = [-0.1, 0, 0.1]  # Offsets for each condition\n",
    "\n",
    "# Create the plot with phases on the x-axis\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Shade the background for mean +- sem of originality from llm_df\n",
    "#ax.fill_between([0.8, 2.2], llm_mean - llm_sem, llm_mean + llm_sem, color='gray', alpha=0.3, label='LLM Originality ± SEM')\n",
    "\n",
    "# Plot error bars and connect the points for each condition\n",
    "for i, condition in enumerate(order):\n",
    "    condition_data = originality_stats_phase[originality_stats_phase['condition_renamed'] == condition]\n",
    "    x_positions = np.array([1 + offsets[i], 2 + offsets[i]])  # Offset the x positions for each condition\n",
    "    ax.errorbar(x_positions, condition_data['mean'], yerr=condition_data['sem'],\n",
    "                fmt=markers[i], capsize=10, markersize=12, linestyle=linestyles[i],\n",
    "                label=condition, color=colors[i], linewidth=3)  # Apply colors, linewidth, and sizes\n",
    "\n",
    "# Set x-ticks to align with 'Practice' and 'Test' phases\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Exposure', 'Test'])\n",
    "\n",
    "# Modify x and y tick labels to be bold and larger\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "ax.set_title('Originality Scores by Condition and Phase')\n",
    "ax.set_xlabel('Phase', fontsize=20)\n",
    "ax.set_ylabel('Originality Score', fontsize=20)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(title='Condition', loc='lower left', fontsize=14, title_fontsize=16)\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit_posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "from scikit_posthocs import posthoc_dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "phase_mapping = {'Practice': 'Exposure', 'Test': 'Test'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "responses_df['phase'] = responses_df['phase'].map(phase_mapping)\n",
    "\n",
    "# Separate data by phase (Exposure and Test)\n",
    "exposure_data = responses_df[responses_df['phase'] == 'Exposure']\n",
    "test_data = responses_df[responses_df['phase'] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis test for Exposure phase\n",
    "exposure_kruskal = kruskal(\n",
    "    exposure_data[exposure_data['condition_renamed'] == 'No LLM Response']['originality'],\n",
    "    exposure_data[exposure_data['condition_renamed'] == 'List of Ideas']['originality'],\n",
    "    exposure_data[exposure_data['condition_renamed'] == 'List of Strategies']['originality']\n",
    ")\n",
    "\n",
    "print(f\"Kruskal-Wallis test result for Exposure phase: H-statistic = {exposure_kruskal.statistic}, p-value = {exposure_kruskal.pvalue}\")\n",
    "\n",
    "# Kruskal-Wallis test for Test phase\n",
    "test_kruskal = kruskal(\n",
    "    test_data[test_data['condition_renamed'] == 'No LLM Response']['originality'],\n",
    "    test_data[test_data['condition_renamed'] == 'List of Ideas']['originality'],\n",
    "    test_data[test_data['condition_renamed'] == 'List of Strategies']['originality']\n",
    ")\n",
    "\n",
    "print(f\"Kruskal-Wallis test result for Test phase: H-statistic = {test_kruskal.statistic}, p-value = {test_kruskal.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn's test for pairwise comparisons with Bonferroni correction for Exposure phase\n",
    "exposure_dunn = posthoc_dunn(\n",
    "    exposure_data, val_col='originality', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Exposure phase:\")\n",
    "print(exposure_dunn)\n",
    "\n",
    "# Dunn's test for pairwise comparisons with Bonferroni correction for Test phase\n",
    "test_dunn = posthoc_dunn(\n",
    "    test_data, val_col='originality', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Test phase:\")\n",
    "print(test_dunn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_mean, llm_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Average Number of Ideas by Condition and Phase\n",
    "\n",
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Calculate number of ideas in rounds 1, 2, 3 individually\n",
    "fluency_practice = responses_df[responses_df['item_order'].isin([1, 2, 3])]\n",
    "fluency_practice = fluency_practice.groupby(['condition_renamed', 'worker_id']).size().reset_index(name='fluency')\n",
    "fluency_practice['phase'] = 'Practice'\n",
    "fluency_practice['fluency'] = fluency_practice['fluency'] / 3  # Average across the three practice rounds\n",
    "\n",
    "# Calculate number of ideas in round 4 (Test)\n",
    "fluency_test = responses_df[responses_df['item_order'] == 4]\n",
    "fluency_test = fluency_test.groupby(['condition_renamed', 'worker_id']).size().reset_index(name='fluency')\n",
    "fluency_test['phase'] = 'Test'\n",
    "\n",
    "# Combine practice and test fluency data\n",
    "fluency_combined = pd.concat([fluency_practice, fluency_test])\n",
    "\n",
    "# Calculate means and SEM for fluency by condition and phase\n",
    "fluency_stats_phase = fluency_combined.groupby(['condition_renamed', 'phase'])['fluency'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "fluency_stats_phase['condition_renamed'] = pd.Categorical(fluency_stats_phase['condition_renamed'], categories=order, ordered=True)\n",
    "fluency_stats_phase = fluency_stats_phase.sort_values(['condition_renamed', 'phase'])\n",
    "\n",
    "# Define color scheme, markers, linestyles, and offsets\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Blue\n",
    "markers = ['o', 's', 'D']  # Circle, Square, Diamond\n",
    "linestyles = ['-', '--', ':']\n",
    "offsets = [-0.1, 0, 0.1]  # Offsets for each condition\n",
    "\n",
    "# Create the plot for fluency by phase\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Plot error bars and connect the points for each condition\n",
    "for i, condition in enumerate(order):\n",
    "    condition_data = fluency_stats_phase[fluency_stats_phase['condition_renamed'] == condition]\n",
    "    x_positions = np.array([1 + offsets[i], 2 + offsets[i]])  # Offset the x positions for each condition\n",
    "    ax.errorbar(x_positions, condition_data['mean'], yerr=condition_data['sem'],\n",
    "                fmt=markers[i], capsize=10, markersize=12, linestyle=linestyles[i],\n",
    "                label=condition, color=colors[i], linewidth=3)\n",
    "\n",
    "# Set x-ticks to align with 'Practice' and 'Test' phases\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Exposure', 'Test'])\n",
    "\n",
    "# Modify x and y tick labels to be bold and larger\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "ax.set_title('Average Number of Ideas by Condition and Phase')\n",
    "ax.set_xlabel('Phase', fontsize=20)\n",
    "ax.set_ylabel('Average Number of Ideas', fontsize=20)\n",
    "\n",
    "# Add legend\n",
    "# ax.legend(title='Condition', loc='upper left')\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by phase (Exposure and Test)\n",
    "fluency_exposure = fluency_combined[fluency_combined['phase'] == 'Practice']\n",
    "fluency_test = fluency_combined[fluency_combined['phase'] == 'Test']\n",
    "# Kruskal-Wallis test for Exposure (Practice) phase\n",
    "fluency_kruskal_exposure = kruskal(\n",
    "    fluency_exposure[fluency_exposure['condition_renamed'] == 'No LLM Response']['fluency'],\n",
    "    fluency_exposure[fluency_exposure['condition_renamed'] == 'List of Ideas']['fluency'],\n",
    "    fluency_exposure[fluency_exposure['condition_renamed'] == 'List of Strategies']['fluency']\n",
    ")\n",
    "\n",
    "print(f\"Kruskal-Wallis test result for Exposure phase: H-statistic = {fluency_kruskal_exposure.statistic}, p-value = {fluency_kruskal_exposure.pvalue}\")\n",
    "\n",
    "# Kruskal-Wallis test for Test phase\n",
    "fluency_kruskal_test = kruskal(\n",
    "    fluency_test[fluency_test['condition_renamed'] == 'No LLM Response']['fluency'],\n",
    "    fluency_test[fluency_test['condition_renamed'] == 'List of Ideas']['fluency'],\n",
    "    fluency_test[fluency_test['condition_renamed'] == 'List of Strategies']['fluency']\n",
    ")\n",
    "\n",
    "print(f\"Kruskal-Wallis test result for Test phase: H-statistic = {fluency_kruskal_test.statistic}, p-value = {fluency_kruskal_test.pvalue}\")\n",
    "# Dunn's test for pairwise comparisons with Bonferroni correction for Exposure phase\n",
    "fluency_dunn_exposure = posthoc_dunn(\n",
    "    fluency_exposure, val_col='fluency', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Exposure phase:\")\n",
    "print(fluency_dunn_exposure)\n",
    "\n",
    "# Dunn's test for pairwise comparisons with Bonferroni correction for Test phase\n",
    "fluency_dunn_test = posthoc_dunn(\n",
    "    fluency_test, val_col='fluency', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Test phase:\")\n",
    "print(fluency_dunn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: Creative Flexibility\n",
    "\n",
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "participants_df['condition_renamed'] = participants_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Rename the 'Creative Flexibility (Diversity)' column to 'creative_flexibility'\n",
    "participants_df = participants_df.rename(columns={'diversity': 'creative_flexibility'})\n",
    "\n",
    "# Adjust the creative flexibility values to a 0-100 scale\n",
    "participants_df['creative_flexibility'] = participants_df['creative_flexibility'] * 100\n",
    "\n",
    "# Calculate means and SEM for creative flexibility by condition\n",
    "creative_flexibility_stats = participants_df.groupby('condition_renamed')['creative_flexibility'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "creative_flexibility_stats['condition_renamed'] = pd.Categorical(creative_flexibility_stats['condition_renamed'], categories=order, ordered=True)\n",
    "creative_flexibility_stats = creative_flexibility_stats.sort_values('condition_renamed')\n",
    "\n",
    "# Define color scheme and markers\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Blue\n",
    "markers = ['o', 's', 'D']  # Circle, Square, Diamond\n",
    "offsets = [-0.1, 0, 0.1]  # Offsets for each condition\n",
    "\n",
    "# Create the plot for creative flexibility with a zoomed-in y-axis\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Plot error bars and points for each condition with offset\n",
    "for i, condition in enumerate(order):\n",
    "    x_position = i + 1 + offsets[i]  # Apply the offset to the x positions\n",
    "    ax.errorbar(x_position, creative_flexibility_stats.loc[creative_flexibility_stats['condition_renamed'] == condition, 'mean'].values[0],\n",
    "                yerr=creative_flexibility_stats.loc[creative_flexibility_stats['condition_renamed'] == condition, 'sem'].values[0],\n",
    "                fmt=markers[i], capsize=10, markersize=12, color=colors[i], linewidth=3)\n",
    "\n",
    "# Set title and labels\n",
    "# ax.set_title('Creative Flexibility Across Conditions')\n",
    "ax.set_xlabel('Condition', fontsize=20)\n",
    "ax.set_ylabel('Creative Flexibility', fontsize=20)\n",
    "\n",
    "# Modify x and y tick labels to be bold and larger\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Set x-ticks to the condition names\n",
    "ax.set_xticks(range(1, len(order) + 1))\n",
    "ax.set_xticklabels(order)\n",
    "\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "# Optionally, drop any rows with NaN values\n",
    "participants_df = participants_df.dropna(subset=['creative_flexibility'])\n",
    "participants_df['condition_renamed'] = participants_df['condition'].map(condition_mapping)\n",
    "# Kruskal-Wallis test for Creative Flexibility\n",
    "kruskal_flexibility = kruskal(\n",
    "    participants_df[participants_df['condition_renamed'] == 'No LLM Response']['creative_flexibility'],\n",
    "    participants_df[participants_df['condition_renamed'] == 'List of Ideas']['creative_flexibility'],\n",
    "    participants_df[participants_df['condition_renamed'] == 'List of Strategies']['creative_flexibility']\n",
    ")\n",
    "\n",
    "print(f\"Kruskal-Wallis test result: H-statistic = {kruskal_flexibility.statistic}, p-value = {kruskal_flexibility.pvalue}\")\n",
    "# Dunn's test for pairwise comparisons with Bonferroni correction\n",
    "dunn_flexibility = posthoc_dunn(\n",
    "    participants_df, val_col='creative_flexibility', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Creative Flexibility:\")\n",
    "print(dunn_flexibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('sentence-transformers/bert-base-nli-max-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Function to calculate pairwise cosine distances and return median, max, and min\n",
    "def calculate_cosine_distance_stats(responses):\n",
    "    if len(responses) < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    embeddings = model.encode(responses)\n",
    "    distances = []\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            distances.append(cosine(embeddings[i], embeddings[j]))\n",
    "    return np.median(distances) * 100, np.max(distances) * 100, np.min(distances) * 100  # Scale to 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: Individual Diversity of Ideas by Condition and Phase \n",
    "\n",
    "# Calculate diversity for each worker, condition, and item order (keeping only the median distance)\n",
    "diversity_results = []\n",
    "for (worker_id, condition, item_order), group in responses_df.groupby(['worker_id', 'condition', 'item_order']):\n",
    "    median_dist, _, _ = calculate_cosine_distance_stats(group['response'].tolist())\n",
    "    phase = 'Practice' if item_order in [1, 2, 3] else 'Test'\n",
    "    diversity_results.append({\n",
    "        'worker_id': worker_id,\n",
    "        'condition': condition,\n",
    "        'phase': phase,\n",
    "        'item_order': item_order,\n",
    "        'median_dist': median_dist\n",
    "    })\n",
    "\n",
    "diversity_stats = pd.DataFrame(diversity_results)\n",
    "\n",
    "# Rename the condition column\n",
    "diversity_stats['condition_renamed'] = diversity_stats['condition'].map(condition_mapping)\n",
    "\n",
    "# Filter out any rows with NaN values\n",
    "diversity_stats = diversity_stats.dropna(subset=['median_dist'])\n",
    "\n",
    "# Average the diversity measures for practice rounds for each participant\n",
    "diversity_stats_practice = diversity_stats[diversity_stats['phase'] == 'Practice'].groupby(['worker_id', 'condition_renamed']).agg({\n",
    "    'median_dist': 'mean'\n",
    "}).reset_index()\n",
    "diversity_stats_practice['phase'] = 'Practice'\n",
    "\n",
    "# Combine the averaged practice results with the test results\n",
    "diversity_stats_test = diversity_stats[diversity_stats['phase'] == 'Test']\n",
    "diversity_combined = pd.concat([diversity_stats_practice, diversity_stats_test])\n",
    "\n",
    "# Calculate mean and SEM for each diversity measure by condition and phase\n",
    "diversity_stats_summary = diversity_combined.groupby(['condition_renamed', 'phase']).agg({\n",
    "    'median_dist': ['mean', 'sem']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "diversity_stats_summary.columns = ['condition_renamed', 'phase', 'mean_median_dist', 'sem_median_dist']\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "diversity_stats_summary['condition_renamed'] = pd.Categorical(diversity_stats_summary['condition_renamed'], categories=order, ordered=True)\n",
    "diversity_stats_summary = diversity_stats_summary.sort_values(['condition_renamed', 'phase'])\n",
    "\n",
    "# Create the plot for diversity by phase\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Define markers, linestyles, and offsets\n",
    "markers = ['o', 's', 'D']\n",
    "linestyles = ['-']  # Solid for Median\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Blue (consistent with previous plots)\n",
    "offsets = [-0.1, 0, 0.1]  # Offsets for each condition\n",
    "\n",
    "# Plot Median Pairwise Cosine Distance (Mean ± SEM)\n",
    "for i, condition in enumerate(order):\n",
    "    condition_data = diversity_stats_summary[diversity_stats_summary['condition_renamed'] == condition]\n",
    "    x_positions = np.array([1 + offsets[i], 2 + offsets[i]])  # Offset the x positions\n",
    "    ax.errorbar(x_positions, condition_data['mean_median_dist'], yerr=condition_data['sem_median_dist'],\n",
    "                fmt=markers[i], capsize=10, markersize=12, linestyle=linestyles[0], label=f'{condition} (Median)', color=colors[i], linewidth=3)\n",
    "\n",
    "# Set x-ticks to align with 'Exposure' and 'Test' phases\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Exposure', 'Test'])\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Individual Diversity of Ideas by Condition and Phase (Median Only)')\n",
    "ax.set_xlabel('Phase', fontsize=20)\n",
    "ax.set_ylabel('Pairwise Cosine Distance', fontsize=20) # Removed (Mean ± SEM)\n",
    "\n",
    "# Modify x and y tick labels to be bold and larger\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='#7F7F7F', label='No LLM Response (Median)', linestyle='-', markersize=12),\n",
    "    Line2D([0], [0], marker='s', color='#e57a77', label='List of Ideas (Median)', linestyle='-', markersize=12),\n",
    "    Line2D([0], [0], marker='D', color='#E5C454', label='List of Strategies (Median)', linestyle='-', markersize=12)\n",
    "]\n",
    "# ax.legend(handles=legend_elements, title='Condition (Median)', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis and Dunn's Test \n",
    "\n",
    "# Separate the data for Practice and Test phases\n",
    "diversity_practice = diversity_combined[diversity_combined['phase'] == 'Practice']\n",
    "diversity_test = diversity_combined[diversity_combined['phase'] == 'Test']\n",
    "\n",
    "# Kruskal-Wallis test for Practice phase\n",
    "kruskal_practice = kruskal(\n",
    "    diversity_practice[diversity_practice['condition_renamed'] == 'No LLM Response']['median_dist'],\n",
    "    diversity_practice[diversity_practice['condition_renamed'] == 'List of Ideas']['median_dist'],\n",
    "    diversity_practice[diversity_practice['condition_renamed'] == 'List of Strategies']['median_dist']\n",
    ")\n",
    "print(f\"Kruskal-Wallis test result for Practice phase: H-statistic = {kruskal_practice.statistic}, p-value = {kruskal_practice.pvalue}\")\n",
    "\n",
    "# Kruskal-Wallis test for Test phase\n",
    "kruskal_test = kruskal(\n",
    "    diversity_test[diversity_test['condition_renamed'] == 'No LLM Response']['median_dist'],\n",
    "    diversity_test[diversity_test['condition_renamed'] == 'List of Ideas']['median_dist'],\n",
    "    diversity_test[diversity_test['condition_renamed'] == 'List of Strategies']['median_dist']\n",
    ")\n",
    "print(f\"Kruskal-Wallis test result for Test phase: H-statistic = {kruskal_test.statistic}, p-value = {kruskal_test.pvalue}\")\n",
    "\n",
    "# Dunn's test for Practice phase with Bonferroni correction\n",
    "dunn_practice = posthoc_dunn(\n",
    "    diversity_practice, val_col='median_dist', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Practice phase:\")\n",
    "print(dunn_practice)\n",
    "\n",
    "# Dunn's test for Test phase with Bonferroni correction\n",
    "dunn_test = posthoc_dunn(\n",
    "    diversity_test, val_col='median_dist', group_col='condition_renamed', p_adjust='bonferroni'\n",
    ")\n",
    "print(\"Dunn's post-hoc test for Test phase:\")\n",
    "print(dunn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Simulations\n",
    "\n",
    "# Rename conditions\n",
    "condition_mapping = {'Absent': 'No LLM Response', 'Generate': 'List of Ideas', 'Coach': 'List of Strategies'}\n",
    "responses_df['condition_renamed'] = responses_df['condition'].map(condition_mapping)\n",
    "\n",
    "# Function to calculate pairwise cosine distances for a set of ideas\n",
    "def calculate_pairwise_distances(responses):\n",
    "    embeddings = model.encode(responses)\n",
    "    distances = []\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            distances.append(cosine(embeddings[i], embeddings[j]))\n",
    "    return distances\n",
    "\n",
    "# Function to generate Monte Carlo samples and calculate diversity measures\n",
    "def monte_carlo_diversity(responses_df, n_samples=7, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    # Sample a specific \"item_name\" first, then sample 7 ideas for that item\n",
    "    unique_items = list(set(responses_df['item_name']))\n",
    "    sampled_item = random.choice(unique_items)\n",
    "    sampled_responses = responses_df[responses_df['item_name'] == sampled_item]['response'].tolist()\n",
    "    sampled_responses = random.sample(sampled_responses, min(len(sampled_responses), n_samples))\n",
    "    distances = calculate_pairwise_distances(sampled_responses)\n",
    "    if not distances:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    return np.mean(distances) * 100, np.median(distances) * 100, np.max(distances) * 100, np.min(distances) * 100\n",
    "\n",
    "# Generate Monte Carlo samples and calculate diversity measures for each combination\n",
    "monte_carlo_results = []\n",
    "for (condition, phase, item_order), group in responses_df.groupby(['condition_renamed', 'phase', 'item_order']):\n",
    "    for seed in range(150):\n",
    "        mean_dist, median_dist, max_dist, min_dist = monte_carlo_diversity(group, seed=seed)\n",
    "        monte_carlo_results.append({'condition': condition, 'phase': phase, 'item_order': item_order,\n",
    "                                    'mean_dist': mean_dist, 'median_dist': median_dist,\n",
    "                                    'max_dist': max_dist, 'min_dist': min_dist})\n",
    "\n",
    "monte_carlo_df = pd.DataFrame(monte_carlo_results)\n",
    "\n",
    "# Calculate mean and SEM for each diversity measure by condition and phase\n",
    "diversity_measures_summary = monte_carlo_df.groupby(['condition', 'phase']).agg(\n",
    "    mean_mean_dist=('mean_dist', 'mean'),\n",
    "    sem_mean_dist=('mean_dist', 'sem'),\n",
    "    mean_median_dist=('median_dist', 'mean'),\n",
    "    sem_median_dist=('median_dist', 'sem'),\n",
    "    mean_max_dist=('max_dist', 'mean'),\n",
    "    sem_max_dist=('max_dist', 'sem'),\n",
    "    mean_min_dist=('min_dist', 'mean'),\n",
    "    sem_min_dist=('min_dist', 'sem')\n",
    ").reset_index()\n",
    "\n",
    "# Sort the conditions\n",
    "order = ['No LLM Response', 'List of Ideas', 'List of Strategies']\n",
    "diversity_measures_summary['condition'] = pd.Categorical(diversity_measures_summary['condition'], categories=order, ordered=True)\n",
    "diversity_measures_summary = diversity_measures_summary.sort_values(['condition', 'phase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8: Group Diversity by Condition and Phase\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define color-blind-friendly colors, markers, and offsets for consistency\n",
    "colors = ['#7F7F7F', '#e57a77', '#3D65A5']  # Gray, Red, Yellow\n",
    "markers = ['o', 's', 'D']  # Circle, Square, Diamond\n",
    "linestyles = ['-']  # Solid for Median\n",
    "offsets = [-0.1, 0, 0.1]  # Small offsets to separate the conditions\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Plot Mean of Median Pairwise Cosine Distance\n",
    "for i, condition in enumerate(order):\n",
    "    condition_data = diversity_measures_summary[diversity_measures_summary['condition'] == condition]\n",
    "    ax.errorbar(x=np.arange(len(condition_data['phase'])) + offsets[i],\n",
    "                y=condition_data['mean_median_dist'],\n",
    "                yerr=condition_data['sem_median_dist'],\n",
    "                fmt=markers[i], capsize=10, markersize=12, linestyle=linestyles[0],\n",
    "                label=f'{condition} (Median)', color=colors[i], linewidth=3)\n",
    "\n",
    "# Set x-ticks to align with 'Practice' and 'Test' phases\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['Exposure', 'Test'])\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Group Diversity (Median) by Condition and Phase')\n",
    "ax.set_xlabel('Phase', fontsize=20)\n",
    "ax.set_ylabel('Pairwise Cosine Distance', fontsize=20)\n",
    "\n",
    "# Modify x and y tick labels to be bold and larger\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Adjust legend to differentiate by condition\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color=colors[0], label='No LLM Response (Median)', linestyle='-', markersize=12),\n",
    "    Line2D([0], [0], marker='s', color=colors[1], label='List of Ideas (Median)', linestyle='-', markersize=12),\n",
    "    Line2D([0], [0], marker='D', color=colors[2], label='List of Strategies (Median)', linestyle='-', markersize=12),\n",
    "]\n",
    "\n",
    "# ax.legend(handles=legend_elements, title='Condition (Median)', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Keep all spines and remove gridlines\n",
    "ax.grid(False)  # Remove gridlines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.5)  # Keep all spines with minimal thickness\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis and Dunn's Test \n",
    "\n",
    "# Separate the data for Exposure and Test phases\n",
    "diversity_exposure = diversity_measures_summary[diversity_measures_summary['phase'] == 'Exposure']\n",
    "diversity_test = diversity_measures_summary[diversity_measures_summary['phase'] == 'Test']\n",
    "# Kruskal-Wallis test for Exposure phase\n",
    "kruskal_exposure = kruskal(\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'No LLM Response']['mean_median_dist'],\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'List of Ideas']['mean_median_dist'],\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'List of Strategies']['mean_median_dist']\n",
    ")\n",
    "print(f\"Kruskal-Wallis test result for Exposure phase: H-statistic = {kruskal_exposure.statistic}, p-value = {kruskal_exposure.pvalue}\")\n",
    "\n",
    "# Kruskal-Wallis test for Test phase\n",
    "kruskal_test = kruskal(\n",
    "    diversity_test[diversity_test['condition'] == 'No LLM Response']['mean_median_dist'],\n",
    "    diversity_test[diversity_test['condition'] == 'List of Ideas']['mean_median_dist'],\n",
    "    diversity_test[diversity_test['condition'] == 'List of Strategies']['mean_median_dist']\n",
    ")\n",
    "print(f\"Kruskal-Wallis test result for Test phase: H-statistic = {kruskal_test.statistic}, p-value = {kruskal_test.pvalue}\")\n",
    "# Dunn's test for Exposure phase\n",
    "if kruskal_exposure.pvalue < 0.05:\n",
    "    dunn_exposure = posthoc_dunn(\n",
    "        diversity_exposure, val_col='mean_median_dist', group_col='condition', p_adjust='bonferroni'\n",
    "    )\n",
    "    print(\"Dunn's post-hoc test for Exposure phase:\")\n",
    "    print(dunn_exposure)\n",
    "\n",
    "# Dunn's test for Test phase\n",
    "if kruskal_test.pvalue < 0.05:\n",
    "    dunn_test = posthoc_dunn(\n",
    "        diversity_test, val_col='mean_median_dist', group_col='condition', p_adjust='bonferroni'\n",
    "    )\n",
    "    print(\"Dunn's post-hoc test for Test phase:\")\n",
    "    print(dunn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude conditions with constant values\n",
    "diversity_exposure_filtered = diversity_exposure.groupby('condition').filter(lambda x: len(x['mean_median_dist'].unique()) > 1)\n",
    "\n",
    "# Then re-run the Kruskal-Wallis test\n",
    "kruskal_exposure_filtered = kruskal(\n",
    "    diversity_exposure_filtered[diversity_exposure_filtered['condition'] == 'No LLM Response']['mean_median_dist'],\n",
    "    diversity_exposure_filtered[diversity_exposure_filtered['condition'] == 'List of Ideas']['mean_median_dist'],\n",
    "    diversity_exposure_filtered[diversity_exposure_filtered['condition'] == 'List of Strategies']['mean_median_dist']\n",
    ")\n",
    "print(f\"Filtered Kruskal-Wallis test result for Exposure phase: H-statistic = {kruskal_exposure_filtered.statistic}, p-value = {kruskal_exposure_filtered.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run Kruskal-Wallis test after handling issues\n",
    "kruskal_exposure = kruskal(\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'No LLM Response']['mean_median_dist'],\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'List of Ideas']['mean_median_dist'],\n",
    "    diversity_exposure[diversity_exposure['condition'] == 'List of Strategies']['mean_median_dist']\n",
    ")\n",
    "print(f\"Kruskal-Wallis test result for Exposure phase: H-statistic = {kruskal_exposure.statistic}, p-value = {kruskal_exposure.pvalue}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
